##本地环境
#kafka.brokers = centos7-A:9092,centos7-B:9092,centos7-C:9092
##准生产
kafka.brokers = 172.29.7.35:6668,172.29.7.41:6668,172.29.7.42:6668
##生产
#kafka.brokers = 172.29.2.23:6668,172.29.2.25:6668,172.29.2.27:6668

##本地环境
#zookeeper.servers = centos7-A:2181,centos7-B:2181,centos7-C:2181
#准生产
zookeeper.servers = 172.29.7.38:2181,172.29.7.39:2181,172.29.7.40:2181
#生产
#zookeeper.servers = 172.29.2.12:2181,172.29.2.13:2181,172.29.2.14:2181

#是否开启kafka的sasl认证
kafka.sasl.enable = true

###TBase配置
tbase.jdbc.datasource.size = 5
tbase.jdbc.url = jdbc:postgresql://172.29.3.14:11387/mydb?currentSchema=public&binaryTransfer=false
tbase.jdbc.user = esscard_admin
tbase.jdbc.password = esscard_admin

#重试次数
restart.attempts = 5
#重试间隔(ms)
delay.between.attempts = 6000
stream.parallelism = 5
stream.checkpoint.interval = 1000
stream.checkpoint.enable = false

sasl.tbds.secure.id = rT8yZ08qcc32PUUc8W9gEIDYPJya2HdF7zdg
sasl.tbds.secure.key = HFgXDqzJq1rNOoB50qqAZcy7y9YJfAoh

job.name = flink-read-kafka
kafka.topic = all_event_logs
#翻滚窗口大小(s)
tumbling.window.size = 60
#最大允许乱序时间(ms)
max.out.of.order = 10000
#最大允许迟到时间(s)
max.allowed.lateness = 10
